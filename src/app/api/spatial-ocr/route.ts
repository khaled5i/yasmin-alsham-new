import { NextRequest, NextResponse } from 'next/server'

/**
 * ğŸ” Spatial OCR API - ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ø¥Ù„Ù‰ Ù†Øµ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
 * 
 * ÙŠØ³ØªØ®Ø¯Ù… Google Cloud Vision API Ù„Ù€:
 * - Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø®Ø· Ø§Ù„ÙŠØ¯ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹
 * - Ø¯Ø¹Ù… Ù…Ù…ØªØ§Ø² Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
 * - Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©
 * - ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØ§Ù„Ø®Ø·ÙˆØ· ØºÙŠØ± Ø§Ù„Ù†ØµÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
 * - Ø¯Ø¹Ù… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø§Ø¦Ù„Ø© ÙˆØ§Ù„Ø¬Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø³Ø·Ø±
 */

interface WordWithMetadata {
    word: any
    centerX: number
    centerY: number
    width: number
    height: number
    clusterId: number | null
}

export async function POST(request: NextRequest) {
    try {
        const { imageData } = await request.json()

        if (!imageData) {
            return NextResponse.json(
                { error: 'No image data provided' },
                { status: 400 }
            )
        }

        const apiKey = process.env.GOOGLE_CLOUD_VISION_API_KEY

        if (!apiKey) {
            return NextResponse.json(
                { error: 'Google Cloud Vision API key not configured' },
                { status: 500 }
            )
        }

        // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© Ù…Ù† base64 Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        const base64Image = imageData.replace(/^data:image\/\w+;base64,/, '')

        // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Google Cloud Vision API
        const visionResponse = await fetch(
            `https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`,
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    requests: [
                        {
                            image: {
                                content: base64Image
                            },
                            features: [
                                {
                                    type: 'DOCUMENT_TEXT_DETECTION',
                                    maxResults: 50
                                }
                            ],
                            imageContext: {
                                languageHints: ['ar', 'en']
                            }
                        }
                    ]
                })
            }
        )

        if (!visionResponse.ok) {
            const errorText = await visionResponse.text()
            console.error('Google Vision API error:', errorText)
            return NextResponse.json(
                { error: 'Failed to process image with Google Vision', details: errorText },
                { status: visionResponse.status }
            )
        }

        const visionData = await visionResponse.json()
        const annotations = visionData.responses[0]

        if (!annotations || !annotations.textAnnotations || annotations.textAnnotations.length === 0) {
            return NextResponse.json({
                texts: [],
                success: true
            })
        }

        const words = annotations.textAnnotations.slice(1)
        const imageWidth = annotations.fullTextAnnotation?.pages?.[0]?.width || 1000
        const imageHeight = annotations.fullTextAnnotation?.pages?.[0]?.height || 1000

        // Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø°ÙƒÙŠØ© Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ Ø¬Ù…Ù„ (ØªØ¯Ø¹Ù… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø§Ø¦Ù„Ø© ÙˆÙ…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø³Ø·Ø±)
        const wordsWithMetadata: WordWithMetadata[] = words.map((word: any) => {
            const vertices = word.boundingPoly.vertices
            const minX = Math.min(vertices[0].x, vertices[1].x, vertices[2].x, vertices[3].x)
            const maxX = Math.max(vertices[0].x, vertices[1].x, vertices[2].x, vertices[3].x)
            const minY = Math.min(vertices[0].y, vertices[1].y, vertices[2].y, vertices[3].y)
            const maxY = Math.max(vertices[0].y, vertices[1].y, vertices[2].y, vertices[3].y)

            return {
                word,
                centerX: (minX + maxX) / 2,
                centerY: (minY + maxY) / 2,
                width: maxX - minX,
                height: maxY - minY,
                clusterId: null
            }
        })

        // Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ© Ø¨ÙŠÙ† ÙƒÙ„Ù…ØªÙŠÙ†
        const distance = (w1: WordWithMetadata, w2: WordWithMetadata) => {
            const dx = w1.centerX - w2.centerX
            const dy = w1.centerY - w2.centerY
            return Math.sqrt(dx * dx + dy * dy)
        }

        // Ø¯Ø§Ù„Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† ÙƒÙ„Ù…ØªÙŠÙ† ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ†Ø§ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø¬Ù…Ù„Ø©
        const shouldBeInSameCluster = (w1: WordWithMetadata, w2: WordWithMetadata) => {
            const dist = distance(w1, w2)
            const avgWidth = (w1.width + w2.width) / 2
            const avgHeight = (w1.height + w2.height) / 2

            const dx = Math.abs(w1.centerX - w2.centerX)
            const dy = Math.abs(w1.centerY - w2.centerY)

            // Ø´Ø±ÙˆØ· Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø°ÙƒÙŠØ©:
            // 1. Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„ÙƒÙ„ÙŠØ© Ø£Ù‚Ù„ Ù…Ù† 3 Ø£Ø¶Ø¹Ø§Ù Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø±Ø¶
            // 2. Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø±Ø£Ø³ÙŠØ© Ø£Ù‚Ù„ Ù…Ù† 1.8 Ø¶Ø¹Ù Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ (Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ù…ÙŠÙ„ ÙˆØ§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©)
            const maxDistance = avgWidth * 3
            const maxVerticalDistance = avgHeight * 1.8

            return dist < maxDistance && dy < maxVerticalDistance
        }

        // Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© DBSCAN Ù…Ø¨Ø³Ø·Ø© Ù„Ù„ØªØ¬Ù…ÙŠØ¹
        let currentClusterId = 0

        wordsWithMetadata.forEach((word) => {
            if (word.clusterId !== null) return

            word.clusterId = currentClusterId
            const cluster = [word]

            let i = 0
            while (i < cluster.length) {
                const currentWord = cluster[i]

                wordsWithMetadata.forEach(otherWord => {
                    if (otherWord.clusterId === null && shouldBeInSameCluster(currentWord, otherWord)) {
                        otherWord.clusterId = currentClusterId
                        cluster.push(otherWord)
                    }
                })

                i++
            }

            currentClusterId++
        })

        // ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø­Ø³Ø¨ cluster ID
        const clusters: Map<number, WordWithMetadata[]> = new Map()
        wordsWithMetadata.forEach(word => {
            if (word.clusterId !== null) {
                if (!clusters.has(word.clusterId)) {
                    clusters.set(word.clusterId, [])
                }
                clusters.get(word.clusterId)!.push(word)
            }
        })

        // ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ cluster Ø¥Ù„Ù‰ Ù†Øµ Ù…Ø¹ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
        const textGroups: Array<{
            text: string
            x: number
            y: number
        }> = []

        clusters.forEach(clusterWords => {
            const isArabic = /[\u0600-\u06FF]/.test(clusterWords[0].word.description)

            // ØªØ±ØªÙŠØ¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: Ø­Ø³Ø¨ Y Ø£ÙˆÙ„Ø§Ù‹ (Ù„Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©)ØŒ Ø«Ù… Ø­Ø³Ø¨ X
            const sortedWords = clusterWords.sort((a, b) => {
                const avgHeight = (a.height + b.height) / 2
                // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø³Ø·Ø± ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹
                if (Math.abs(a.centerY - b.centerY) < avgHeight * 0.5) {
                    return isArabic ? b.centerX - a.centerX : a.centerX - b.centerX
                } else {
                    return a.centerY - b.centerY
                }
            })

            const text = sortedWords.map(w => w.word.description).join(' ')

            // Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ÙƒÙ„ÙŠ
            const allX = sortedWords.map(w => w.centerX)
            const allY = sortedWords.map(w => w.centerY)
            const centerX = allX.reduce((a, b) => a + b, 0) / allX.length
            const centerY = allY.reduce((a, b) => a + b, 0) / allY.length

            const x = (centerX / imageWidth) * 100
            const y = (centerY / imageHeight) * 100

            textGroups.push({
                text: text.trim(),
                x: Math.min(Math.max(x, 0), 100),
                y: Math.min(Math.max(y, 0), 100)
            })
        })

        const filteredTexts = textGroups.filter(t => t.text.length > 0)

        return NextResponse.json({
            texts: filteredTexts,
            success: true,
            debug: {
                totalWords: words.length,
                totalClusters: clusters.size,
                imageSize: { width: imageWidth, height: imageHeight }
            }
        })

    } catch (error) {
        console.error('Spatial OCR error:', error)

        if (error instanceof Error) {
            return NextResponse.json(
                {
                    error: 'Failed to process image',
                    message: error.message,
                    details: error.toString()
                },
                { status: 500 }
            )
        }

        return NextResponse.json(
            { error: 'Failed to process image', message: 'Unknown error' },
            { status: 500 }
        )
    }
}
